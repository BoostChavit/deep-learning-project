{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras, tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LSTM\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(img, smaller):\n",
    "        \n",
    "    # Convert the image to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    if(smaller):\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "\n",
    "        # Applying dilation on the threshold image\n",
    "        dilation = cv2.morphologyEx(thresh1, cv2.MORPH_OPEN, rect_kernel, iterations = 1)\n",
    "        # dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
    "    else:\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
    "\n",
    "        # Applying dilation on the threshold image\n",
    "        dilation = cv2.dilate(thresh1, rect_kernel, iterations = 2)\n",
    "\n",
    "    # Finding contours\n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, \n",
    "                                                    cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingbox(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    contours = extract(img, False)\n",
    "\n",
    "    sum = 0\n",
    "    y_pred = []\n",
    "    boxes = []\n",
    "    im = img.copy()\n",
    "    crops = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        # rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            \n",
    "        # Cropping the text block\n",
    "        cropped = img[y:y + h, x:x + w]\n",
    "\n",
    "        # extract each alphabet from each block\n",
    "        contours2 = extract(cropped, True)\n",
    "        \n",
    "        for i in contours2:\n",
    "            # count alphabets \n",
    "            sum += 1\n",
    "\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(i)\n",
    "            \n",
    "            cropped2 = img[y+y2: y+y2+h2, x+x2: x+x2+w2]\n",
    "            \n",
    "            center_x = (x + x2 + w2 / 2) / img.shape[1]\n",
    "            center_y = (y + y2 + h2 / 2) / img.shape[0]\n",
    "            normalized_width = w2 / img.shape[1]\n",
    "            normalized_height = h2 / img.shape[0]\n",
    "\n",
    "            # Append the YOLO format coordinates to the boxes list\n",
    "            boxes.append([center_x, center_y, normalized_width, normalized_height])\n",
    "\n",
    "\n",
    "            # boxes.append([x+x2, y+y2, x+x2 + w2, y+y2 + h2]) \n",
    "\n",
    "            cropped2 = cv2.resize(cropped2, (64,64))\n",
    "            \n",
    "            crops.append(cropped2)\n",
    "\n",
    "            cropped2 = cropped2.reshape((1, 64, 64, 3))\n",
    "\n",
    "    \n",
    "    \n",
    "    order = np.argsort([x[0] for x in boxes])\n",
    "    boxes = [boxes[x] for x in order]\n",
    "    crops = [crops[x] for x in order]\n",
    "    \n",
    "    return sum, boxes, im, crops\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each classes(62 classes) has 55 images \n",
    "model_training_csv = os.path.join(os.getcwd(), 'alphabets/english.csv')\n",
    "\n",
    "# make dataframe for training model \n",
    "model_training_df = pd.read_csv(model_training_csv)\n",
    "\n",
    "class_names = model_training_df.label.unique()\n",
    "\n",
    "Y = [label for label in range(len(class_names))]\n",
    "\n",
    "# one-hot-encoded the label\n",
    "y_train = keras.utils.to_categorical(class_names, len(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏û‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ\n",
    "source_folder_images = os.path.join(os.getcwd(), \"archive/train_v2/train\")\n",
    "\n",
    "# ‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏û‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô dataset YOLO\n",
    "destination_folder_images = os.path.join(os.getcwd(), \"data/images\")\n",
    "\n",
    "\n",
    "destination_folder_labels = os.path.join(os.getcwd(), \"data/labels\")\n",
    "\n",
    "# destination_folder_labels = os.path.join(os.getcwd(), \"dataset_yolo\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = os.path.join(os.getcwd(), \"archive/train_v2/train\")\n",
    "test_img_path = os.path.join(os.getcwd(), \"archive/test_v2/test\")\n",
    "\n",
    "train_csv_path = os.path.join(os.getcwd(), \"archive/written_name_train_v2.csv\")\n",
    "test_csv_path = os.path.join(os.getcwd(), \"archive/written_name_test_v2.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_csv_path)\n",
    "cnt = 0\n",
    "im = 0\n",
    "boxes = []\n",
    "\n",
    "# for i in range (df.shape[0]):\n",
    "for i in range (10000):\n",
    "    img_name = os.path.join(train_img_path, df['FILENAME'][i])\n",
    "    num_of_char, boxes, img, crop = boundingbox(img_name)\n",
    "    # num_of_char, y_pred, boxes, img, crop = boundingbox(img_name, model)\n",
    "    \n",
    "    if num_of_char == len(str(df['IDENTITY'][i])):\n",
    "        cnt += 1\n",
    "        fileName = df['FILENAME'][i]\n",
    "        shutil.copy(os.path.join(source_folder_images, fileName), os.path.join(destination_folder_images, fileName))\n",
    "\n",
    "        label = ''\n",
    "        for j in range(len(df['IDENTITY'][i])):\n",
    "            if df['IDENTITY'][i][j] == ' ' or df['IDENTITY'][i][j] == '-':\n",
    "                continue\n",
    "            name = np.where(class_names == df['IDENTITY'][i][j])[0][0]\n",
    "            # print(name[0])\n",
    "            label += str(name) + ' '\n",
    "            temp = ' '.join(map(str, boxes[j]))\n",
    "            label += temp\n",
    "            label += '\\n'\n",
    "         \n",
    "\n",
    "        fileName = fileName.split('.')\n",
    "        new_filename = f\"{fileName[0]}.txt\"\n",
    "        label_path = os.path.join(destination_folder_labels, new_filename)\n",
    "\n",
    "        with open(label_path, \"w\") as label_file:\n",
    "            label_file.write(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.25 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.24 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/Users/boost/Documents/deep_learning/project/data/coco128.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=62\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2140042  ultralytics.nn.modules.head.Detect           [62, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11159594 parameters, 11159578 gradients, 28.8 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/boost/Documents/deep_learning/project/data/labels... 120 images, 1063 backgrounds, 120 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1183/1183 [00:00<00:00, 5602.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00020.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00023.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00025.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00030.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00034.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00040.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00053.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00061.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00062.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00086.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00096.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00100.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00103.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00122.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00125.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00129.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00143.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00157.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00173.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00176.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00179.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00180.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00197.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00214.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00218.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00220.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00223.jpg: ignoring corrupt image/label: could not convert string to float: '[30]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00224.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00234.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00235.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00251.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00254.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00262.jpg: ignoring corrupt image/label: could not convert string to float: '[34]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00263.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00267.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00269.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00275.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00277.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00281.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00297.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00302.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00319.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00325.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00359.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00362.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00369.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00386.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00393.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00411.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00425.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00429.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00454.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00461.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00477.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00479.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00499.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00520.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00521.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00525.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00547.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00571.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00574.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00581.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00582.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00593.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00599.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00603.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00609.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00633.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00635.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00637.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00643.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00648.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00650.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00651.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00669.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00675.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00677.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00681.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00695.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00716.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00720.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00722.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00735.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00737.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00747.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00754.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00755.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00758.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00763.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00779.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00782.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00783.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00791.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00798.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00809.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00813.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00821.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00824.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00841.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00856.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00861.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00863.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00866.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00870.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00889.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00892.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00895.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00898.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00907.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00908.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00916.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00923.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00925.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00944.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00950.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00955.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00980.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00992.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00997.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/boost/Documents/deep_learning/project/data/labels.cache\n",
      "WARNING ‚ö†Ô∏è No labels found in /Users/boost/Documents/deep_learning/project/data/labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/boost/Documents/deep_learning/project/data/labels.cache... 120 images, 1063 backgrounds, 120 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1183/1183 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00020.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00023.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00025.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00030.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00034.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00040.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00053.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00061.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00062.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00086.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00096.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00100.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00103.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00122.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00125.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00129.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00143.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00157.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00173.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00176.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00179.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00180.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00197.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00214.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00218.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00220.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00223.jpg: ignoring corrupt image/label: could not convert string to float: '[30]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00224.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00234.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00235.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00251.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00254.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00262.jpg: ignoring corrupt image/label: could not convert string to float: '[34]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00263.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00267.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00269.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00275.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00277.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00281.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00297.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00302.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00319.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00325.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00359.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00362.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00369.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00386.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00393.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00411.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00425.jpg: ignoring corrupt image/label: could not convert string to float: '[19]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00429.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00454.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00461.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00477.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00479.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00499.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00520.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00521.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00525.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00547.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00571.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00574.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00581.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00582.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00593.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00599.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00603.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00609.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00633.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00635.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00637.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00643.jpg: ignoring corrupt image/label: could not convert string to float: '[15]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00648.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00650.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00651.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00669.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00675.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00677.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00681.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00695.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00716.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00720.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00722.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00735.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00737.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00747.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00754.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00755.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00758.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00763.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00779.jpg: ignoring corrupt image/label: could not convert string to float: '[17]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00782.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00783.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00791.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00798.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00809.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00813.jpg: ignoring corrupt image/label: could not convert string to float: '[14]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00821.jpg: ignoring corrupt image/label: could not convert string to float: '[20]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00824.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00841.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00856.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00861.jpg: ignoring corrupt image/label: could not convert string to float: '[28]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00863.jpg: ignoring corrupt image/label: could not convert string to float: '[25]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00866.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00870.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00889.jpg: ignoring corrupt image/label: could not convert string to float: '[10]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00892.jpg: ignoring corrupt image/label: could not convert string to float: '[29]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00895.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00898.jpg: ignoring corrupt image/label: could not convert string to float: '[27]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00907.jpg: ignoring corrupt image/label: could not convert string to float: '[16]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00908.jpg: ignoring corrupt image/label: could not convert string to float: '[21]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00916.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00923.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00925.jpg: ignoring corrupt image/label: could not convert string to float: '[13]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00944.jpg: ignoring corrupt image/label: could not convert string to float: '[12]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00950.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00955.jpg: ignoring corrupt image/label: could not convert string to float: '[11]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00980.jpg: ignoring corrupt image/label: could not convert string to float: '[23]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00992.jpg: ignoring corrupt image/label: could not convert string to float: '[22]'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/boost/Documents/deep_learning/project/data/images/TRAIN_00997.jpg: ignoring corrupt image/label: could not convert string to float: '[31]'\n",
      "WARNING ‚ö†Ô∏è No labels found in /Users/boost/Documents/deep_learning/project/data/labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000152, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G          0      282.2          0          0        640:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38/67 [11:12<08:33, 17.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m data_yaml \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(yolo_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco128.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/engine/model.py:654\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/engine/trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/engine/trainer.py:376\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    375\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/tasks.py:88\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/tasks.py:266\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 266\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_folder = os.path.join(os.getcwd(), \"data\")\n",
    "model = YOLO(\"yolov8s.pt\")  # load the model\n",
    "\n",
    "# Specify the path to your training YAML file\n",
    "data_yaml = os.path.join(yolo_folder, \"coco128.yaml\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=data_yaml, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
